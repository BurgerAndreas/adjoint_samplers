# @package _global_

project: adjoint_sampler
train_itr_per_epoch: 10
init_stage: adjoint

# === hardward related  ===
resample_batch_size: 512
train_batch_size: 512
eval_batch_size: 2000
num_eval_samples: ${eval_batch_size}

evaluator:
  # _target_: adjoint_samplers.components.evaluator.SyntheticEenergyEvaluator
  # ref_samples_path: data/test_split_DW4.npy
  do_particles_w2: false

# === training ===
num_epochs: 20

# === logging  ===
use_wandb: False
eval_freq: 19
save_ckpt: false

shared_dir: /checkpoint
hydra:
  run:
    # dir: ./results/local/${now:%Y.%m.%d}/${now:%H%M%S}
    dir: ./results/debug
  # sweep:
  #   dir: ./results/${now:%Y.%m.%d}/${now:%H%M%S}
  #   subdir: ${hydra.job.num}
  # launcher:
  #   max_num_timeout: 100000
  #   timeout_min: 4319
  #   gpus_per_node: 1
  #   tasks_per_node: ${hydra.launcher.gpus_per_node}
  #   cpus_per_task: 10
  #   nodes: 1
  #   constraint: volta16gb
  #   mem_per_gpu: 30gb